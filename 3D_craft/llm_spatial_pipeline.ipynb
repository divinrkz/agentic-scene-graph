{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ea17dc",
   "metadata": {},
   "source": [
    "# SnapTo3D Spatial‑Planning Pipeline\n",
    "\n",
    "Flow: \n",
    "```\n",
    "USER prompt -> LLM (scene‑graph JSON) -> Constraint Solver -> Blender CodeGen -> Render -> VLM Verifier\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b3dbd7",
   "metadata": {},
   "source": [
    "## 0  Setup and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↳ Run once per environment\n",
    "!source spatial-env/bin/activate\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fa1af",
   "metadata": {},
   "source": [
    "## 1  Scene‑graph schema & helper classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9be5964",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'save_scene_graph' from 'helper' (/Users/divinirakiza/Workspaces/CALTECH/cs159/snapTo3D/3D_craft/helper.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m save_scene_graph\n\u001b[32m      9\u001b[39m load_dotenv()\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'save_scene_graph' from 'helper' (/Users/divinirakiza/Workspaces/CALTECH/cs159/snapTo3D/3D_craft/helper.py)"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from helper import save_scene_graph\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c01394",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'save_scene_graph' from 'helper' (/Users/divinirakiza/Workspaces/CALTECH/cs159/snapTo3D/3D_craft/helper.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 6\u001b[39m\n",
      "\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n",
      "\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m save_scene_graph\n",
      "\u001b[32m      9\u001b[39m load_dotenv()\n",
      "\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'save_scene_graph' from 'helper' (/Users/divinirakiza/Workspaces/CALTECH/cs159/snapTo3D/3D_craft/helper.py)"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from helper import save_scene_graph\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5c8390",
   "metadata": {},
   "source": [
    "## 2  LLM reasoning → JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd059cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-4'\n",
    "\n",
    "OpenAPIClient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def llm_to_scene(prompt: str) -> dict:\n",
    "    \"\"\"Call GPT with function‑calling and return a scene‑graph dict.\"\"\"\n",
    "    function = {\n",
    "        'name': 'create_scene_graph',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'nodes': {'type':'array', 'items':{'type':'object'}},\n",
    "                'constraints': {'type':'array', 'items':{'type':'object'}},\n",
    "                'room': {'type':'object'}\n",
    "            },\n",
    "            'required': ['nodes','constraints']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    system_message = \"\"\"You are a spatial-planning assistant that creates scene graphs for 3D room layouts.\n",
    "    Each node in the scene should have:\n",
    "    - id: unique identifier\n",
    "    - size: [width, depth, height] in meters\n",
    "    - asset: name of the 3D model to use\n",
    "    \n",
    "    Each constraint should have:\n",
    "    - type: 'left_of' or 'front_of'\n",
    "    - a: id of first object\n",
    "    - b: id of second object\n",
    "    - gap: optional spacing in meters\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = OpenAPIClient.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {'role':'system', 'content': system_message},\n",
    "                {'role':'user', 'content': prompt}\n",
    "            ],\n",
    "            functions=[function],\n",
    "            function_call={'name':'create_scene_graph'}\n",
    "        )\n",
    "        \n",
    "        if not response.choices or not response.choices[0].message.function_call:\n",
    "            raise ValueError(\"No valid response from API\")\n",
    "            \n",
    "        print('response', response.choices[0].message)\n",
    "        return json.loads(response.choices[0].message.function_call.arguments)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in llm_to_scene: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7233dea",
   "metadata": {},
   "source": [
    "## 3  Constraint solver → absolute coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4eca5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.sat.python import cp_model\n",
    "\n",
    "GRID = 100 \n",
    "from ortools.sat.python import cp_model\n",
    "\n",
    "def solve_scene(scene: dict) -> dict:\n",
    "    m = cp_model.CpModel()\n",
    "    pos, half = {}, {}\n",
    "\n",
    "    # centres (x,y) in 1 cm grid\n",
    "    for n in scene['nodes']:\n",
    "        w,d,_ = n['size']\n",
    "        half[n['id']] = (int(w*GRID/2), int(d*GRID/2))\n",
    "        pos[n['id']]  = (                       # centre coordinates\n",
    "            m.NewIntVar(-500*GRID, 500*GRID, f'x_{n[\"id\"]}'),\n",
    "            m.NewIntVar(-500*GRID, 500*GRID, f'y_{n[\"id\"]}')\n",
    "        )\n",
    "\n",
    "    # relational constraints --------------------------------------------------\n",
    "    for c in scene['constraints']:\n",
    "        a,b = c['a'], c['b']\n",
    "        gap = int(c.get('gap', .3)*GRID)\n",
    "        xa,ya = pos[a]; xb,yb = pos[b]\n",
    "        wa,da = half[a]; wb,db = half[b]\n",
    "\n",
    "        if c['type'] == 'left_of':\n",
    "            m.Add(xa + wa + gap <= xb - wb)\n",
    "        elif c['type'] == 'front_of':\n",
    "            m.Add(ya + da + gap <= yb - db)\n",
    "        # … add others …\n",
    "\n",
    "    # NON-OVERLAP (boolean disjunction) ---------------------------------------\n",
    "    ids = list(pos.keys())\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i+1, len(ids)):\n",
    "            A, B = ids[i], ids[j]\n",
    "            xa, ya = pos[A]; xb, yb = pos[B]\n",
    "            wa, da = half[A]; wb, db = half[B]\n",
    "\n",
    "            left   = m.NewBoolVar(f'{A}_left_{B}')\n",
    "            right  = m.NewBoolVar(f'{A}_right_{B}')\n",
    "            front  = m.NewBoolVar(f'{A}_front_{B}')\n",
    "            behind = m.NewBoolVar(f'{A}_behind_{B}')\n",
    "\n",
    "            m.Add(xa + wa <= xb - wb).OnlyEnforceIf(left)\n",
    "            m.Add(xb + wb <= xa - wa).OnlyEnforceIf(right)\n",
    "            m.Add(ya + da <= yb - db).OnlyEnforceIf(front)\n",
    "            m.Add(yb + db <= ya - da).OnlyEnforceIf(behind)\n",
    "\n",
    "            # at least one spatial separation must hold\n",
    "            m.AddBoolOr([left, right, front, behind])\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    solver = cp_model.CpSolver()\n",
    "    assert solver.Solve(m) == cp_model.OPTIMAL, \"No feasible layout found\"\n",
    "    return {oid: (solver.Value(x)/GRID, solver.Value(y)/GRID)\n",
    "            for oid,(x,y) in pos.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd133ce",
   "metadata": {},
   "source": [
    "## 4  CodeGen → Blender .py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9f6b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_blender_py(scene: dict, placements: dict, outfile='scene.py'):\n",
    "    lines = [\"import bpy\"]\n",
    "    for n in scene['nodes']:\n",
    "        nid = n['id']\n",
    "        asset = n['asset']\n",
    "        x,y = placements[nid]\n",
    "        z = n['size'][2]/2\n",
    "        lines += [\n",
    "            f'bpy.ops.wm.append(filename=\"{asset}\")',\n",
    "            f'bpy.context.selected_objects[0].location = ({x:.2f}, {y:.2f}, {z:.2f})'\n",
    "        ]\n",
    "    with open(outfile,'w') as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39943399",
   "metadata": {},
   "source": [
    "## 5  Headless Blender render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb3995bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, pathlib\n",
    "\n",
    "def render_blend(pyfile: str, outpng: str='assets/renders/render.png'):\n",
    "    blender_bin = '/Applications/Blender.app/Contents/MacOS/Blender'  # adjust path if needed\n",
    "    cmd = [blender_bin, '-b', '--python', pyfile, '-o', outpng, '-f', '1']\n",
    "    print(' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "    return pathlib.Path(outpng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f729c50e",
   "metadata": {},
   "source": [
    "## 6  Vision‑language verifier (stub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b585a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_scene(image_path: str, scene: dict) -> float:\n",
    "    \"\"\"Return fraction of relations judged correct by GPT‑4V (stub).\"\"\"\n",
    "    # TODO: implement with openai.Vision API once available.\n",
    "    return 1.0  # assume perfect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cab694",
   "metadata": {},
   "source": [
    "## 7  End‑to‑end pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e55f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_and_render(prompt: str):\n",
    "    scene = llm_to_scene(prompt)\n",
    "    # print('scene', scene)\n",
    "    scene_file = helper.save_scene_graph(scene)\n",
    "    placements = solve_scene(scene)\n",
    "    py_script = gen_blender_py(scene, placements)\n",
    "    img = render_blend(py_script)\n",
    "    score = verify_scene(img, scene)\n",
    "    print(f'Verification score: {score}')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82c99f",
   "metadata": {},
   "source": [
    "## 8  Example run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff01581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\\n  \"nodes\": [\\n    {\\n      \"id\": \"1\",\\n      \"size\": [2.0, 1.0, 0.6],\\n      \"asset\": \"sofa\"\\n    },\\n    {\\n      \"id\": \"2\",\\n      \"size\": [1.0, 0.5, 0.3],\\n      \"asset\": \"coffee_table\"\\n    },\\n    {\\n      \"id\": \"3\",\\n      \"size\": [4.0, 3.0, 2.5],\\n      \"asset\": \"room\"\\n    }\\n  ],\\n  \"constraints\": [\\n    {\\n      \"type\": \"front_of\",\\n      \"a\": \"1\",\\n      \"b\": \"2\",\\n      \"gap\": 0.3\\n    }\\n  ]\\n}', name='create_scene_graph'), tool_calls=None)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'helper' has no attribute 'save_scene_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m example_prompt = \u001b[33m\"\u001b[39m\u001b[33mPlace a 2m sofa in front of a 1m coffee table with a 0.3m gap, inside a 4*3 m room.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mplan_and_render\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_prompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mplan_and_render\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m      2\u001b[39m scene = llm_to_scene(prompt)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# print('scene', scene)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m scene_file = \u001b[43mhelper\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_scene_graph\u001b[49m(scene)\n\u001b[32m      5\u001b[39m placements = solve_scene(scene)\n\u001b[32m      6\u001b[39m py_script = gen_blender_py(scene, placements)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'helper' has no attribute 'save_scene_graph'"
     ]
    }
   ],
   "source": [
    "example_prompt = \"Place a 2m sofa in front of a 1m coffee table with a 0.3m gap, inside a 4*3 m room.\"\n",
    "\n",
    "plan_and_render(example_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
