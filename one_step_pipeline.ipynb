{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ea17dc",
   "metadata": {},
   "source": [
    "#  One way Pipeline\n",
    "\n",
    "Flow: \n",
    "```\n",
    "USER prompt -> Blender CodeGen -> Render -> VLM Verifier\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b3dbd7",
   "metadata": {},
   "source": [
    "## 0  Setup and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8476cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↳ Run once per environment\n",
    "!source spatial-env/bin/activate\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fa1af",
   "metadata": {},
   "source": [
    "## 1  Scene‑graph schema & helper classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b9be5964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import time\n",
    "# import uuid \n",
    "\n",
    "import subprocess\n",
    "import pathlib\n",
    "import cloudinary\n",
    "import cloudinary.uploader\n",
    "\n",
    "from cloudinary.utils import cloudinary_url\n",
    "import os\n",
    "from loguru import logger\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bf54afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    \"id\": 1,\n",
    "    \"test_type\": \"multi-relation\",\n",
    "    \"prompt\": \"\",\n",
    "    \"image_url\": \"\",\n",
    "    \"test_questions\": {\n",
    "        \"question_1\": {\n",
    "            \"question\": \"\",\n",
    "            \"answer\": \"\"\n",
    "        },\n",
    "        \"question_2\": {\n",
    "            \"question\": \"\",\n",
    "            \"answer\": \"\"\n",
    "        },\n",
    "        \"question_3\": {\n",
    "            \"question\": \"\",\n",
    "            \"answer\": \"\"\n",
    "        },\n",
    "        \"question_4\": {\n",
    "            \"question\": \"\",\n",
    "            \"answer\": \"\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5c8390",
   "metadata": {},
   "source": [
    "## 2  Blender code generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cd059cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-4'\n",
    "\n",
    "OpenAPIClient = OpenAI(api_key=\"\")\n",
    "\n",
    "def llm_to_scene(prompt: str) -> dict:\n",
    "\n",
    "    system_message = \"\"\"\n",
    "                        You are a 3D spatial planning assistant. \n",
    "                        Generate blender code for scene with room layouts with proper furniture placement, considering spatial relationships, accessibility, and design principles.\n",
    "                        Only return the blender code, no other text.\n",
    "        \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = OpenAPIClient.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {'role':'system', 'content': system_message},\n",
    "                {'role':'user', 'content': prompt}\n",
    "            ],\n",
    "        )\n",
    "        print(response.choices[0].message.content)\n",
    "    \n",
    "            \n",
    "        logger.info(f\"blender code generated successfully ...\")\n",
    "        print(response.choices[0].message.content)\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in llm_to_scene: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7233dea",
   "metadata": {},
   "source": [
    "## 3  Constraint solver → absolute coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "4eca5744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd133ce",
   "metadata": {},
   "source": [
    "## 4  CodeGen → Blender .py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "d9f6b967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39943399",
   "metadata": {},
   "source": [
    "## 5  Headless Blender render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cb3995bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudinary.config(\n",
    "    cloud_name=os.getenv('CLOUDINARY_CLOUD_NAME'),\n",
    "    api_key=os.getenv('CLOUDINARY_API_KEY'),\n",
    "    api_secret=os.getenv('CLOUDINARY_API_SECRET')\n",
    ")\n",
    "\n",
    "def render_and_upload_image(pyfile: str, image_outfile: str = 'assets/one_step_renders/scene.png',\n",
    "                           cloudinary_folder: str = 'one_step_renders', prompt: str = ''):\n",
    "    \"\"\"\n",
    "    Uploading rendered images (PNG, JPG, etc.)\n",
    "    \n",
    "    Args:\n",
    "        pyfile: Path to the Python script for Blender\n",
    "        image_outfile: Output path for the rendered image\n",
    "        cloudinary_folder: Folder name in Cloudinary\n",
    "    \n",
    "    Returns:\n",
    "        dict: Cloudinary upload response\n",
    "    \"\"\"\n",
    "    logger.info(f\"Rendering and uploading image to Cloudinary ...\")\n",
    "    blender_bin = '/Applications/Blender.app/Contents/MacOS/Blender'\n",
    "    \n",
    "    output_path = pathlib.Path(image_outfile)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    cmd = [blender_bin, '-b', '--python', pyfile]\n",
    "    logger.info(f\"Running Blender: {' '.join(cmd)}\")\n",
    "    \n",
    "    # if error in blender, regenerate the code with error message and max 3 attempts\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            subprocess.run(cmd, check=True)\n",
    "            logger.success(f\"Blender rendering completed: {output_path}\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            logger.error(f\"Blender rendering failed: {e}\")\n",
    "            if attempt < 2:\n",
    "                logger.info(f\"Regenerating Blender code due to error: {e}\")\n",
    "                blender_code = llm_to_scene(prompt)\n",
    "                save_blender_code(blender_code)\n",
    "                continue\n",
    "            else:\n",
    "                logger.error(f\"Blender rendering failed after 3 attempts: {e}\")\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Blender rendering failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Uploading {output_path} to Cloudinary...\")\n",
    "        \n",
    "        upload_result = cloudinary.uploader.upload(\n",
    "            str(output_path),\n",
    "            folder=cloudinary_folder,\n",
    "            public_id=f\"{output_path.stem}_{int(time.time())}\",\n",
    "            overwrite=True,\n",
    "            tags=[\"blender\", \"render\", \"image\"],\n",
    "        )\n",
    "        \n",
    "        logger.success(f\"Upload successfull {upload_result['public_id']} !!\")\n",
    "\n",
    "        return upload_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Cloudinary upload failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f729c50e",
   "metadata": {},
   "source": [
    "## 6  Vision‑language verifier (stub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8b585a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_scene(prompt: str, image_path: str) -> float:\n",
    "    \"\"\"Return fraction of relations judged correct by GPT-4V (stub).\"\"\"\n",
    "\n",
    "    logger.info(f\"Verifying scene ...\") \n",
    "\n",
    "    system_message = 'You are an expert in evaluating PIL image objects, which contain rooms generated in Blender, and assigning them a score based on their spatial accuracy.'\n",
    "    # prompt = f\"Ascribe a decimal number ranging from 10-20 that scores the image in the following link {image_path} based on how well the generated scene satisfies the following JSON layout: {scene}\"\n",
    "    prompt += f\"The image is at the following link: {image_path}. Just answer the question, no other text.\"\n",
    "\n",
    "    response = OpenAPIClient.chat.completions.create(\n",
    "            model='o4-mini',\n",
    "            messages=[\n",
    "                {'role':'system', 'content': system_message},\n",
    "                {'role':'user', 'content': prompt}\n",
    "            ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content # assume perfect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd20b9ed",
   "metadata": {},
   "source": [
    "## 7. Evaluation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b7dec554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(prompt: str, url: str):\n",
    "    verification_score_prompt = \"Ascribe a decimal number ranging from 0-10 that scores the image in the following link {url} based on how well the generated scene satisfies the following JSON layout: {scene}\"\n",
    "    score = verify_scene(verification_score_prompt, url)\n",
    "    result['test_questions']['question_1'] = {\n",
    "        'question': verification_score_prompt,\n",
    "        'answer': score\n",
    "    }\n",
    "\n",
    "    for i in range(3):\n",
    "        multi_relation_prompt = f'''I want to assess the spatial accuracy of a scene created by a user prompt {prompt}. Write a yes/no question that will assess the multi-relation accuracy of the scene.\n",
    "        Rules: multi-relations queries are queries where that ask about the spatial relationships of the objects/furniture that must appear given the prompt. Only return the question, no other text.'''\n",
    "        question = OpenAPIClient.chat.completions.create(\n",
    "            model='o4-mini',\n",
    "            messages=[\n",
    "                {'role':'system', 'content': 'You are an expert in asking questions on 3D scenes based on their spatial relationships.'},\n",
    "                {'role':'user', 'content': multi_relation_prompt}\n",
    "            ],\n",
    "        )\n",
    "        answer = verify_scene(question.choices[0].message.content, url)\n",
    "        result['test_questions'][f'question_{i+2}']['question'] = question.choices[0].message.content\n",
    "        result['test_questions'][f'question_{i+2}']['answer'] = answer\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8ed7a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_blender_code(code, filename=\"blender_scene.py\"):\n",
    "    \"\"\"Save the generated Blender Python code to a file\"\"\"\n",
    "    logger.info(f\"Saving Blender Python code to {filename} ...\")\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(\"blender_scripts\", exist_ok=True)\n",
    "    \n",
    "    # Full path to save the file\n",
    "    filepath = os.path.join(\"blender_scripts\", filename)\n",
    "    \n",
    "    # Write the code to file\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(code)\n",
    "    \n",
    "    logger.success(f\"Blender Python code saved to: {filepath}\")\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cab694",
   "metadata": {},
   "source": [
    "## 7  End‑to‑end pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6e55f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_and_render(prompt: str):\n",
    "    \"\"\"\n",
    "    Direct pipeline from prompt to render.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Initial prompt for scene generation\n",
    "    \"\"\"\n",
    "    logger.info(f\"Processing prompt and rendering scene...\")\n",
    "    \n",
    "    try:\n",
    "        # Generate scene from prompt\n",
    "        logger.info(\"Generating scene from prompt ...\")\n",
    "        blender_code = llm_to_scene(prompt)\n",
    "        print(blender_code)\n",
    "        logger.success('Scene generated successfully.')\n",
    "\n",
    "        # save the blender code\n",
    "        save_blender_code(blender_code)\n",
    "\n",
    "        # render the scene\n",
    "        rendered_scene = render_and_upload_image(pyfile=\"assets/blender/script.py\", \n",
    "                                               image_outfile=\"assets/renders/scene.png\",    prompt=prompt)\n",
    "        if not rendered_scene:\n",
    "            raise ValueError(\"Render function returned empty result\")\n",
    "            \n",
    "        # Evaluate scene\n",
    "        logger.info(\"Evaluating scene...\")\n",
    "        evaluation(prompt, rendered_scene['secure_url'])\n",
    "        logger.success('Scene evaluation completed.')\n",
    "        \n",
    "        logger.success(f\"\\nSuccess! Scene rendered successfully.\")\n",
    "        return rendered_scene\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in pipeline: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff02fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc82c99f",
   "metadata": {},
   "source": [
    "## 8  Example run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ff01581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-03 23:30:05.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplan_and_render\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mProcessing prompt and rendering scene...\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:05.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplan_and_render\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mGenerating scene from prompt ...\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:20.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mllm_to_scene\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mblender code generated successfully ...\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:20.696\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplan_and_render\u001b[0m:\u001b[36m15\u001b[0m - \u001b[32m\u001b[1mScene generated successfully.\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:20.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_blender_code\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mSaving Blender Python code to blender_scene.py ...\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:20.698\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_blender_code\u001b[0m:\u001b[36m14\u001b[0m - \u001b[32m\u001b[1mBlender Python code saved to: blender_scripts/blender_scene.py\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:20.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrender_and_upload_image\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mRendering and uploading image to Cloudinary ...\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:20.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrender_and_upload_image\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mRunning Blender: /Applications/Blender.app/Contents/MacOS/Blender -b --python assets/blender/script.py\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import bpy\n",
      "\n",
      "# Function for creating objects\n",
      "def create_obj(name, dimensions):\n",
      "    bpy.ops.mesh.primitive_cube_add(\n",
      "        size=1,\n",
      "        enter_editmode=False,\n",
      "        align='WORLD',\n",
      "        location=(0, 0, dimensions[2]/2)\n",
      "    )\n",
      "    obj = bpy.context.object\n",
      "    obj.dimensions = dimensions\n",
      "    obj.name = name\n",
      "    return obj\n",
      "\n",
      "# Create room\n",
      "room = create_obj('Room', (4.0, 3.2, 3.0))\n",
      "\n",
      "# Create bed\n",
      "bed = create_obj('Bed', (1.9, 0.9, 0.6))\n",
      "bed.location.x = 0 # Centered on the back wall\n",
      "bed.location.y = -((room.dimensions.y - bed.dimensions.y) / 2) # Pushed against the back wall\n",
      "\n",
      "# Create desk\n",
      "desk = create_obj('Desk', (1.2, 0.6, 0.75))\n",
      "desk.rotation_euler.z = 1.5708 # Perpendicular to the bed\n",
      "desk.location.x = bed.location.x + bed.dimensions.x /2 + desk.dimensions.y / 2 # Meets the bed foot\n",
      "desk.location.y = room.dimensions.y / 2 - desk.dimensions.x / 2 # Pushed against the right wall\n",
      "\n",
      "# Create floor lamp\n",
      "lamp = create_obj('Lamp', (0.3, 0.3, 1.7))\n",
      "lamp.location.x = -room.dimensions.x / 2 + lamp.dimensions.x / 2 # Left side of the room\n",
      "lamp.location.y = bed.location.y + bed.dimensions.y / 2 + lamp.dimensions.y / 2 # Align with bed\n",
      "```\n",
      "```python\n",
      "import bpy\n",
      "\n",
      "# Function for creating objects\n",
      "def create_obj(name, dimensions):\n",
      "    bpy.ops.mesh.primitive_cube_add(\n",
      "        size=1,\n",
      "        enter_editmode=False,\n",
      "        align='WORLD',\n",
      "        location=(0, 0, dimensions[2]/2)\n",
      "    )\n",
      "    obj = bpy.context.object\n",
      "    obj.dimensions = dimensions\n",
      "    obj.name = name\n",
      "    return obj\n",
      "\n",
      "# Create room\n",
      "room = create_obj('Room', (4.0, 3.2, 3.0))\n",
      "\n",
      "# Create bed\n",
      "bed = create_obj('Bed', (1.9, 0.9, 0.6))\n",
      "bed.location.x = 0 # Centered on the back wall\n",
      "bed.location.y = -((room.dimensions.y - bed.dimensions.y) / 2) # Pushed against the back wall\n",
      "\n",
      "# Create desk\n",
      "desk = create_obj('Desk', (1.2, 0.6, 0.75))\n",
      "desk.rotation_euler.z = 1.5708 # Perpendicular to the bed\n",
      "desk.location.x = bed.location.x + bed.dimensions.x /2 + desk.dimensions.y / 2 # Meets the bed foot\n",
      "desk.location.y = room.dimensions.y / 2 - desk.dimensions.x / 2 # Pushed against the right wall\n",
      "\n",
      "# Create floor lamp\n",
      "lamp = create_obj('Lamp', (0.3, 0.3, 1.7))\n",
      "lamp.location.x = -room.dimensions.x / 2 + lamp.dimensions.x / 2 # Left side of the room\n",
      "lamp.location.y = bed.location.y + bed.dimensions.y / 2 + lamp.dimensions.y / 2 # Align with bed\n",
      "```\n",
      "```python\n",
      "import bpy\n",
      "\n",
      "# Function for creating objects\n",
      "def create_obj(name, dimensions):\n",
      "    bpy.ops.mesh.primitive_cube_add(\n",
      "        size=1,\n",
      "        enter_editmode=False,\n",
      "        align='WORLD',\n",
      "        location=(0, 0, dimensions[2]/2)\n",
      "    )\n",
      "    obj = bpy.context.object\n",
      "    obj.dimensions = dimensions\n",
      "    obj.name = name\n",
      "    return obj\n",
      "\n",
      "# Create room\n",
      "room = create_obj('Room', (4.0, 3.2, 3.0))\n",
      "\n",
      "# Create bed\n",
      "bed = create_obj('Bed', (1.9, 0.9, 0.6))\n",
      "bed.location.x = 0 # Centered on the back wall\n",
      "bed.location.y = -((room.dimensions.y - bed.dimensions.y) / 2) # Pushed against the back wall\n",
      "\n",
      "# Create desk\n",
      "desk = create_obj('Desk', (1.2, 0.6, 0.75))\n",
      "desk.rotation_euler.z = 1.5708 # Perpendicular to the bed\n",
      "desk.location.x = bed.location.x + bed.dimensions.x /2 + desk.dimensions.y / 2 # Meets the bed foot\n",
      "desk.location.y = room.dimensions.y / 2 - desk.dimensions.x / 2 # Pushed against the right wall\n",
      "\n",
      "# Create floor lamp\n",
      "lamp = create_obj('Lamp', (0.3, 0.3, 1.7))\n",
      "lamp.location.x = -room.dimensions.x / 2 + lamp.dimensions.x / 2 # Left side of the room\n",
      "lamp.location.y = bed.location.y + bed.dimensions.y / 2 + lamp.dimensions.y / 2 # Align with bed\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/divinirakiza/Workspaces/CALTECH/cs159/snapTo3D/3D_craft/assets/blender/script.py\", line 86, in <module>\n",
      "    bsdf.inputs['Roughness'].default_value = None\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: bpy_struct: item.attr = val: NodeSocketFloatFactor.default_value expected a float type, not NoneType\n",
      "\u001b[32m2025-06-03 23:30:21.386\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrender_and_upload_image\u001b[0m:\u001b[36m33\u001b[0m - \u001b[32m\u001b[1mBlender rendering completed: assets/renders/scene.png\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:21.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrender_and_upload_image\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mUploading assets/renders/scene.png to Cloudinary...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blender 4.4.1 (hash d8845b3bb572 built 2025-04-15 01:30:48)\n",
      "\n",
      "Blender quit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-03 23:30:22.121\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrender_and_upload_image\u001b[0m:\u001b[36m61\u001b[0m - \u001b[32m\u001b[1mUpload successfull one_step_renders/scene_1749018621 !!\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:22.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplan_and_render\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mEvaluating scene...\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:22.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mverify_scene\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mVerifying scene ...\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:27.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mverify_scene\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mVerifying scene ...\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:36.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mverify_scene\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mVerifying scene ...\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:44.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mverify_scene\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mVerifying scene ...\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:54.243\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplan_and_render\u001b[0m:\u001b[36m29\u001b[0m - \u001b[32m\u001b[1mScene evaluation completed.\u001b[0m\n",
      "\u001b[32m2025-06-03 23:30:54.244\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mplan_and_render\u001b[0m:\u001b[36m31\u001b[0m - \u001b[32m\u001b[1m\n",
      "Success! Scene rendered successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "example_prompt1 = \"Design a bedroom (4.0 * 3.2 * 3.0 m), and put the bed snug against the left wall. Stand the wardrobe centred on the back wall. Rotate the desk so its front edge meets the foot of the bed, and rest a bedside lamp on the desk’s left corner. Position furniture logically with proper spacing and accessibility.\"\n",
    "example_prompt2 = \"Create a living room (4.5 * 3.5 * 3.0 m) Line the sofa along the left wall, place the coffee table directly in front of it, and fix the TV console against the right wall facing the sofa. A floor lamp should stand behind the sofa’s right arm.\"\n",
    "example_prompt3 = \"Design a dining room (3.6 × 3.6 × 3.0 m). Place the dining table in the middle of the room with the six chairs arranged around it; push the sideboard against the back wall behind the table, and hang the pendant light above the table.\"\n",
    "example_prompt4 = \"Design Bedroom (4.0 × 3.2 × 3.0 m). Place the bed centred on the back wall. Rotate the desk perpendicular to the bed and push it against the right wall where it meets the bed’s foot. Stand a floor lamp on the left side of the bed.\"\n",
    "\n",
    "\n",
    "rendered_scene = plan_and_render(example_prompt1)\n",
    "# result['prompt'] = example_prompt4\n",
    "# result['image_url'] = rendered_scene['secure_url']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7ee4bcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'test_type': 'multi-relation',\n",
       " 'prompt': '',\n",
       " 'image_url': '',\n",
       " 'test_questions': {'question_1': {'question': 'Ascribe a decimal number ranging from 0-10 that scores the image in the following link {url} based on how well the generated scene satisfies the following JSON layout: {scene}',\n",
       "   'answer': '8.3'},\n",
       "  'question_2': {'question': 'Is the desk perpendicular to the bed and pushed against the right wall at the bed’s foot, with a floor lamp standing on the left side of the bed?',\n",
       "   'answer': 'No.'},\n",
       "  'question_3': {'question': 'Is the bed centered on the back wall with the desk placed perpendicular to it and flush against the right wall at its foot, while the floor lamp stands on the left side of the bed?',\n",
       "   'answer': 'Yes.'},\n",
       "  'question_4': {'question': 'Is the bed centered on the back wall, the desk perpendicular to the bed and pushed against the right wall at the foot of the bed, and the floor lamp standing on the left side of the bed?',\n",
       "   'answer': 'No.'}}}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b9e994a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'test_type': 'multi-relation',\n",
       " 'prompt': '',\n",
       " 'image_url': '',\n",
       " 'test_questions': {'question_1': {'question': 'Ascribe a decimal number ranging from 0-10 that scores the image in the following link {url} based on how well the generated scene satisfies the following JSON layout: {scene}',\n",
       "   'answer': '8.3'},\n",
       "  'question_2': {'question': 'Is the desk perpendicular to the bed and pushed against the right wall at the bed’s foot, with a floor lamp standing on the left side of the bed?',\n",
       "   'answer': 'No.'},\n",
       "  'question_3': {'question': 'Is the bed centered on the back wall with the desk placed perpendicular to it and flush against the right wall at its foot, while the floor lamp stands on the left side of the bed?',\n",
       "   'answer': 'Yes.'},\n",
       "  'question_4': {'question': 'Is the bed centered on the back wall, the desk perpendicular to the bed and pushed against the right wall at the foot of the bed, and the floor lamp standing on the left side of the bed?',\n",
       "   'answer': 'No.'}}}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562c2a7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8ced45c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tests/one_step_results.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[147]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m results = {\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m: []}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtests/one_step_results.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m     results = json.load(f)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mhere\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspaces/CALTECH/cs159/snapTo3D/3D_craft/spatial-env/lib/python3.12/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'tests/one_step_results.json'"
     ]
    }
   ],
   "source": [
    "results = {\"results\": []}\n",
    "\n",
    "with open('tests/one_step_results.json', 'r') as f:\n",
    "    \n",
    "    results = json.load(f)\n",
    "print('here')\n",
    "results[\"results\"].append(result)\n",
    "\n",
    "with open('tests/one_step_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1afa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
